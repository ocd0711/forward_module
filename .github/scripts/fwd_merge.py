import json
import requests
from packaging import version
import re
import os

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/26.0 Safari/605.1.15"
}

# ================================================================
# å·¥å…·å‡½æ•°
# ================================================================

def is_url_accessible(url: str) -> bool:
    try:
        resp = requests.head(url, allow_redirects=True, timeout=10)
        return 200 <= resp.status_code < 400
    except requests.RequestException:
        return False

def check_url_final(url: str):
    """æ£€æµ‹ URL æœ€ç»ˆçŠ¶æ€å¹¶è¿”å› (å¯è®¿é—®?, æœ€ç»ˆURL, çŠ¶æ€ç )"""
    try:
        resp = requests.head(url, headers=HEADERS, allow_redirects=True, timeout=10)

        if resp.status_code == 405:
            resp = requests.get(url, headers=HEADERS, allow_redirects=True, stream=True, timeout=10)
            resp.close()

        final_url = resp.url
        return (200 <= resp.status_code < 300), final_url, resp.status_code

    except requests.RequestException:
        return False, None, None

def sanitize_text(value: str) -> str:
    return re.sub(r"forward", "fw", value, flags=re.IGNORECASE) if isinstance(value, str) else value

def normalize_version(v: str):
    if not v:
        return version.parse("0.0.0")
    v_clean = re.sub(r"^[vV]", "", v.strip())
    try:
        return version.parse(v_clean)
    except Exception:
        return version.parse("0.0.0")

def _detect_branch(base_dir: str) -> str:
    if os.getenv("GITHUB_REF_NAME"):
        return os.getenv("GITHUB_REF_NAME")
    if os.getenv("GITHUB_REF"):
        return os.getenv("GITHUB_REF").split("/")[-1]

    head_file = os.path.join(base_dir, ".git", "HEAD")
    try:
        with open(head_file, "r", encoding="utf-8") as f:
            line = f.read().strip()
            if line.startswith("ref:"):
                return line.split("/")[-1]
    except Exception:
        pass

    return "master"

def _detect_owner_repo() -> str:
    return os.getenv("GITHUB_REPOSITORY", "ocd0711/forward_module")

OWNER_REPO = _detect_owner_repo()
BRANCH = _detect_branch(BASE_DIR)

def url_to_repo(raw_url: str) -> str:
    m = re.match(r"https://raw\.githubusercontent\.com/([^/]+)/([^/]+)/", raw_url)
    if m:
        return f"https://github.com/{m.group(1)}/{m.group(2)}"
    return raw_url

def normalize_filename(filename):
    name, ext = os.path.splitext(filename)
    return f"{name.lower()}{ext.lower()}"

def file_exists_case_insensitive(directory, filename):
    target = normalize_filename(filename)
    try:
        for f in os.listdir(directory):
            if normalize_filename(f) == target:
                return True
        return False
    except OSError:
        return False

def get_unique_filename(directory, filename, widget_id):
    base_name = normalize_filename(filename)
    name, ext = os.path.splitext(base_name)

    if name == widget_id.lower():
        return base_name

    if file_exists_case_insensitive(directory, base_name):
        return f"{widget_id.lower()}{ext}"

    return base_name

# ================================================================
# ä¸‹è½½ URL â†’ ç”Ÿæˆå¤‡ä»½åœ°å€
# ================================================================

def download_and_replace_url(widget, base_dir):
    original_url = widget.get("url")
    if not original_url:
        return widget

    try:
        resp = requests.get(original_url, headers=HEADERS, timeout=20, stream=True)
        resp.raise_for_status()

        filename = os.path.basename(original_url.split("?")[0])
        if not filename or filename.lower() == "raw":
            filename = f"{widget.get('id')}.js"

        local_dir = os.path.join(base_dir, "widgets")
        os.makedirs(local_dir, exist_ok=True)

        unique_filename = get_unique_filename(local_dir, filename, widget.get("id"))
        local_path = os.path.join(local_dir, unique_filename)

        with open(local_path, "wb") as f:
            for chunk in resp.iter_content(chunk_size=8192):
                f.write(chunk)

        repo_url = f"https://raw.githubusercontent.com/{OWNER_REPO}/{BRANCH}/widgets/{unique_filename}"

        # ä¿å­˜å¤‡ä»½ URLï¼Œä¸è¦†ç›–åŸå§‹ URL
        widget["backup_url"] = repo_url

        print(f"  ğŸ’¾ å¤‡ä»½æ–‡ä»¶å·²ä¿å­˜: {widget.get('id')} -> {unique_filename}")

    except Exception as e:
        print(f"  âš ï¸ ä¸‹è½½å¤±è´¥ {widget.get('id')} ({original_url}): {e}")

    return widget


# ================================================================
# ä¸»é€»è¾‘ï¼šè¯»å– module.json â†’ åˆå¹¶ â†’ ä¿ç•™æœ€æ–°ç‰ˆæœ¬
# ================================================================

with open(os.path.join(BASE_DIR, "module.json"), "r", encoding="utf-8") as f:
    modules = json.load(f)

all_widgets = []
thanks = []

for name, url in modules.items():
    print(f"æ­£åœ¨è·å–: {name} -> {url}")
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        resp.raise_for_status()
        resp.encoding = "utf-8"
        text = re.sub(r",\s*([\]}])", r"\1", resp.text)
        data = json.loads(text)
        widgets = data.get("widgets", [])

        all_widgets.extend(widgets)
        thanks.append(f"- [{name}]({url_to_repo(url)})")

        print(f"  âœ… å·²åŠ è½½ {len(widgets)} ä¸ª widgets")
    except Exception as e:
        print(f"  âš ï¸ æ— æ³•è¯»å– {name}: {e}")

# ================================================================
# å»é‡ â†’ ä¿ç•™æœ€æ–°ç‰ˆæœ¬ â†’ è¿‡æ»¤ä¸å¯è®¿é—® URL
# ================================================================

merged = {}
for widget in all_widgets:
    wid = widget.get("id")
    url = widget.get("url")
    if not wid or not url:
        continue

    ok, final, code = check_url_final(url)
    if not ok:
        print(f"  âš ï¸ å·²è·³è¿‡å¤±æ•ˆ widget: {wid} (æœ€ç»ˆ URL: {final}, çŠ¶æ€ç : {code})")
        continue

    widget["url"] = final

    cur_ver = normalize_version(widget.get("version", "0.0.0"))
    if wid not in merged or cur_ver > normalize_version(merged[wid].get("version", "0.0.0")):
        merged[wid] = widget


# ================================================================
# ä¸‹è½½å¹¶ç”Ÿæˆ backup_url
# ================================================================

for wid, widget in merged.items():
    merged[wid] = download_and_replace_url(widget, BASE_DIR)


# ================================================================
# ä»æ—§çš„ allinone.fwd æ¢å¤ç¼ºå¤±ä½†æœ¬åœ°å­˜åœ¨å¤‡ä»½çš„å†…å®¹
# ================================================================

old_fwd_path = os.path.join(BASE_DIR, "allinone.fwd")

if os.path.exists(old_fwd_path):
    try:
        with open(old_fwd_path, "r", encoding="utf-8") as f:
            old_data = json.load(f)

        for old_widget in old_data.get("widgets", []):
            wid = old_widget.get("id")
            if wid not in merged:
                filename = os.path.basename(old_widget.get("url", "")).split("?")[0]
                if filename and file_exists_case_insensitive(os.path.join(BASE_DIR, "widgets"), filename):
                    merged[wid] = old_widget
                    print(f"  â™»ï¸ æ¢å¤æœ¬åœ°å¤‡ä»½ widget: {wid}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å–æ—§ allinone.fwd: {e}")


# ================================================================
# ç”Ÿæˆ **ç¬¬ä¸€ä»½ fwd**ï¼šallinone.fwdï¼ˆåŸå§‹ URLï¼‰
# ================================================================

result_main = {
    "title": "OCD's AllInOne Widgets",
    "description": "åˆå¹¶åçš„æ¨¡å—ï¼ˆä½¿ç”¨åŸå§‹ URLï¼‰",
    "icon": "https://avatars.githubusercontent.com/u/25606004",
    "widgets": list(merged.values())
}

main_file = os.path.join(BASE_DIR, "allinone.fwd")

with open(main_file, "w", encoding="utf-8") as f:
    json.dump(result_main, f, ensure_ascii=False, indent=2)

print(f"ğŸ‰ ç”Ÿæˆå®Œæˆï¼š{main_file}")


# ================================================================
# ç”Ÿæˆ **ç¬¬äºŒä»½ fwd**ï¼šallinone_back.fwdï¼ˆå¤‡ä»½ URLï¼‰
# ================================================================

backup_widgets = []
for w in merged.values():
    w2 = w.copy()

    if "backup_url" in w2:
        w2["url"] = w2["backup_url"]

    w2.pop("backup_url", None)
    backup_widgets.append(w2)

result_backup = {
    "title": "OCD's AllInOne Widgets (Backup)",
    "description": "æ‰€æœ‰ widgets ä½¿ç”¨å¤‡ä»½ RAW URL",
    "icon": "https://avatars.githubusercontent.com/u/25606004",
    "widgets": backup_widgets
}

backup_file = os.path.join(BASE_DIR, "allinone_back.fwd")

with open(backup_file, "w", encoding="utf-8") as f:
    json.dump(result_backup, f, ensure_ascii=False, indent=2)

print(f"ğŸ‰ ç”Ÿæˆå®Œæˆï¼š{backup_file}")


# ================================================================
# æ›´æ–° README.md
# ================================================================

readme = (
    "# OCD's AllInOne Widgets\n\n"
    "è‡ªåŠ¨åˆå¹¶å¤šä¸ª Forward Widgets æºå¹¶ç”Ÿæˆä¸¤ä»½å¯ç”¨æ¨¡å—ï¼š\n\n"
    "- **allinone.fwd**ï¼ˆä½¿ç”¨åŸå§‹ URLï¼‰\n"
    "- **allinone_back.fwd**ï¼ˆä½¿ç”¨ä»“åº“ RAW å¤‡ä»½ URLï¼‰\n\n"
    "## åŸå§‹æ¥æºä»“åº“\n" + "\n".join(thanks)
)

with open(os.path.join(BASE_DIR, "README.md"), "w", encoding="utf-8") as f:
    f.write(readme)

print("ğŸ“˜ README.md å·²æ›´æ–°")